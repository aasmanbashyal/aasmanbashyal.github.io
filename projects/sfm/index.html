<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Structure from Motion (SfM) | Aasman Bashyal </title> <meta name="author" content="Aasman Bashyal"> <meta name="description" content="3D reconstruction using SfM"> <meta name="keywords" content="aasman, aasmanbashyal, AI, bashyalaasman, computervision,"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo2.png?28e9e362b78f27b0600444a4e53ecd7d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aasmanbashyal.github.io/projects/sfm/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Aasman</span> Bashyal </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">Resume </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">Gallery </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Structure from Motion (SfM)</h1> <p class="post-description">3D reconstruction using SfM</p> </header> <article> <p>Structure from Motion (SfM) is a computer vision technique for reconstructing 3D structures from 2D image (sequencial and non-sequencial) . This project demonstrates the end-to-end pipeline for SfM, including feature detection, camera pose estimation, triangulation, and 3D point cloud generation with code, mathematical representation and open source alternatives.</p> <div class="row"> <div class="col-xl mt-3 mt-md-0"> <div class="embed-responsive embed-responsive-16by9"> <figure> <iframe src="https://www.youtube.com/embed/x0KW0VWS5S4" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"></iframe> </figure> </div> </div> </div> <h2 id="steps">Steps</h2> <p>The following steps are typically used in standard structure from motion.</p> <ol> <li>Camera Model</li> <li>Feature Detection</li> <li>Feature Matching</li> <li>Fundamental Matrix Estimation</li> <li>Essential Matrix Estimation</li> <li>Triangulation</li> <li>Bundle Adjustment</li> <li>Sparse Point Cloud</li> <li>Dense Reconstruction</li> </ol> <hr> <h2 id="1-camera-model">1. Camera Model</h2> <p>It is a mathematical representation that describes how a 3D point in the world is projected onto a 2D image plane. Simple <strong>pinhole camera model</strong> is represented by following mathematical formula:</p> \[\mathbf{x} = K [R \,|\, t] \mathbf{X}\] <p>Where:</p> <ul> <li>\(\mathbf{x}\): 2D point in the image (in homogeneous coordinates).</li> <li>\(K\): Intrinsic camera matrix (focal length, principal point).</li> <li>\(R, t\): Camera rotation and translation (extrinsic parameters).</li> <li>\(\mathbf{X}\): 3D point in the scene.</li> </ul> <hr> <h2 id="2-feature-detection">2. Feature Detection</h2> <p>Feature Detection can be defined as involves identifying unique, stable points or regions in an image that can be reliably matched across different views or frames. It is crucial because it provides the “landmarks” or “anchors” within the image that can be matched with other images. The goal is to find points that are distinct, robust under transformations (like rotation, scaling, and lighting changes), and can be reliably tracked across multiple views. Typically three types of Features matching are there:</p> <ol> <li>Keypoints</li> <li>Descriptors</li> <li>Regions of Interest(Rols)</li> </ol> <p>It detects feature points \(\mathbf{x}_i\) in each image using algorithms like Scale-Invariant Feature Transform (SIFT),Speeded Up Robust Features (SURF) and Oriented FAST and Rotated BRIEF (ORB).</p> <hr> <h2 id="3-feature-matching">3. Feature Matching</h2> <p>Once featuresare detected across several images taken from different viewpoints., the next step is to match them across images. This is where the descriptors come in, as they uniquely identify the features.</p> <ul> <li>Match descriptors \(\mathbf{x}_i \leftrightarrow \mathbf{x}_j\) between image pairs.</li> <li>Use a similarity metric (e.g., Euclidean distance, K-D Tree - a binary tree structure) to find correspondences.</li> <li>Filter out outliers using techniques like RANSAC.</li> </ul> <hr> <h2 id="4-fundamental-matrix-estimation">4. Fundamental Matrix Estimation</h2> <p>The <strong>Fundamental Matrix</strong> \(\mathbf{F}\) satisfies the epipolar constraint:</p> \[\mathbf{x}_j^T \mathbf{F} \mathbf{x}_i = 0\] <p>To estimate \(\mathbf{F}\):</p> <ol> <li>Use the <strong>eight-point algorithm</strong>: <ul> <li>Construct a linear system from matched points.</li> <li>Solve \(\mathbf{A} \mathbf{f} = 0\), where \(\mathbf{f}\) represents entries of \(\mathbf{F}\).</li> </ul> </li> <li>Enforce the rank-2 constraint on \(\mathbf{F}\) by applying Singular Value Decomposition (SVD).</li> </ol> <hr> <h2 id="5-essential-matrix-estimation">5. Essential Matrix Estimation</h2> <p>The <strong>Essential Matrix</strong> \(\mathbf{E}\) is derived from \(\mathbf{F}\) and camera intrinsics \(K\):</p> \[\mathbf{E} = K^T \mathbf{F} K\] <p>Decompose \(\mathbf{E}\) into relative rotation \(\mathbf{R}\) and translation \(\mathbf{t}\):</p> \[\mathbf{E} = \mathbf{R} [\mathbf{t}]_\times\] <p>Where:</p> <ul> <li>\([\mathbf{t}]_\times\) is the skew-symmetric matrix of \(\mathbf{t}\).</li> <li>Solve using SVD of \(\mathbf{E}\).</li> </ul> <hr> <h2 id="6-triangulation">6. Triangulation</h2> <p>For each matched feature pair, compute the 3D point \(\mathbf{X}\) by solving:</p> \[\mathbf{A} \mathbf{X} = 0\] <p>Where:</p> \[\mathbf{A} = \begin{bmatrix} \mathbf{x}_1 \times P_1 \\ \mathbf{x}_2 \times P_2 \end{bmatrix}\] <p>Solve for \(\mathbf{X}\) using SVD.</p> <hr> <h2 id="7-bundle-adjustment">7. Bundle Adjustment</h2> <p>Refine camera parameters \(\{K, R, t\}\) and 3D points \(\mathbf{X}\) by minimizing the <strong>reprojection error</strong>:</p> \[\min_{K, R, t, \mathbf{X}} \sum_{i,j} \| \mathbf{x}_{ij} - \pi(K, R_j, t_j, \mathbf{X}_i) \|^2\] <p>Where:</p> <ul> <li>\(\mathbf{x}_{ij}\): Observed 2D projection of 3D point \(\mathbf{X}_i\) in image \(j\).</li> <li>\(\pi\): Projection function using the camera model.</li> </ul> <p>Solve using non-linear least squares methods like the <strong>Levenberg-Marquardt algorithm</strong>.</p> <hr> <h2 id="8-sparse-point-cloud">8. Sparse Point Cloud</h2> <p>Combine triangulated points \(\mathbf{X}\) into a <strong>sparse point cloud</strong> representing the scene.</p> <hr> <h2 id="9-dense-reconstruction-optional">9. Dense Reconstruction (Optional)</h2> <p>To densify the sparse point cloud, use <strong>Multi-View Stereo (MVS)</strong> to estimate depth \(z\) for every pixel by minimizing:</p> \[z = \arg \min_z \sum_i \| I_i(u, v) - I_j(\pi(u, v, z)) \|^2\] <p>Where:</p> <ul> <li>\(I_i\): Image intensity at a pixel.</li> <li>\(\pi(u, v, z)\): Projected pixel location in another image.</li> </ul> <hr> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Aasman Bashyal. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-resume",title:"Resume",description:"",section:"Navigation",handler:()=>{window.location.href="/resume/"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-gallery",title:"Gallery",description:"Collection of photos.",section:"Navigation",handler:()=>{window.location.href="/gallery/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"projects-automatic-modulation-classifer",title:"Automatic Modulation Classifer",description:"Major Project - Identifying the Modulation Type of a Signal",section:"Projects",handler:()=>{window.location.href="/projects/amc/"}},{id:"projects-automatic-polygon-mask-drawing",title:"Automatic Polygon(Mask) Drawing",description:"Using the Segment Anything Model for automatic polygon(Mask) drawing.",section:"Projects",handler:()=>{window.location.href="/projects/automatic_polygon_drawing/"}},{id:"projects-gaussian-splatting",title:"Gaussian Splatting",description:"3D reconstruction using Gaussian Splatting",section:"Projects",handler:()=>{window.location.href="/projects/gaussiansplatting/"}},{id:"projects-robotics-projects",title:"Robotics Projects",description:"Robots our team built for ABU Robocon.",section:"Projects",handler:()=>{window.location.href="/projects/robotics/"}},{id:"projects-structure-from-motion-sfm",title:"Structure from Motion (SfM)",description:"3D reconstruction using SfM",section:"Projects",handler:()=>{window.location.href="/projects/sfm/"}},{id:"projects-slam",title:"SLAM",description:"Minor Project - Simultaneous Localization and Mapping (SLAM) Using Grid-Map and Particle Filter",section:"Projects",handler:()=>{window.location.href="/projects/slam/"}},{id:"projects-cad-snapping",title:"CAD snapping",description:"Enabling Snapping",section:"Projects",handler:()=>{window.location.href="/projects/snapping/"}},{id:"projects-3d-terrain-editing",title:"3D Terrain Editing",description:"Flattening 3D surface",section:"Projects",handler:()=>{window.location.href="/projects/terrainediting/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>